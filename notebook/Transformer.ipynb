{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ddfe726-abe1-4154-8d83-69d413940d0b",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05e45a32-9158-426d-a318-833d82c0e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torchtext.disable_torchtext_deprecation_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efda4879-e53d-435a-9a25-1952dbf4f9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6070288f-80d2-4a4b-bc21-938c58ac7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Cynthia\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.802 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return [tok for tok in jieba.cut(text)]\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        # sep='\\t'表示使用制表符分隔，header=0表示第一行为列名\n",
    "        self.data = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.tokenizer(self.data.iloc[idx, 1])\n",
    "        trg = self.tokenizer(self.data.iloc[idx, 0])\n",
    "        return {'src': src, 'trg': trg}\n",
    "\n",
    "\n",
    "# 创建词汇表\n",
    "def yield_tokens(data_iter):\n",
    "    for tokens in data_iter:\n",
    "        # yield 的作用是将函数变成一个生成器\n",
    "        yield tokens\n",
    "\n",
    "train_data = TextDataset('../data/data_sample.tsv', tokenizer)\n",
    "# train_data = TextDataset('../data/train.tsv', tokenizer)\n",
    "# val_data = TextDataset('../data/dev.tsv', tokenizer)\n",
    "\n",
    "\n",
    "# 使用词频生成词汇表\n",
    "# min_freq=2表示只有出现次数大于等于2的词才会被加入到词汇表中\n",
    "vocab = build_vocab_from_iterator(yield_tokens(item['src'] for item in train_data),\n",
    "                                  min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "# 定义索引转换和特殊标记索引\n",
    "PAD_IDX = vocab['<pad>']\n",
    "UNK_IDX = vocab['<unk>']\n",
    "SOS_IDX = vocab['<sos>']\n",
    "EOS_IDX = vocab['<eos>']\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for item in batch:\n",
    "        # 添加起始 (SOS) 和结束 (EOS) 标记，并转换为索引\n",
    "        src_batch.append([SOS_IDX] + vocab(item['src']) + [EOS_IDX])\n",
    "        trg_batch.append([SOS_IDX] + vocab(item['trg']) + [EOS_IDX])\n",
    "\n",
    "    # 使用 pad_sequence 对每个批次的序列填充到相同长度\n",
    "    src_batch = torch.nn.utils.rnn.pad_sequence([torch.tensor(x) for x in src_batch],\n",
    "                                                padding_value=PAD_IDX, batch_first=True)\n",
    "    trg_batch = torch.nn.utils.rnn.pad_sequence([torch.tensor(x) for x in trg_batch],\n",
    "                                                padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch.to(device), trg_batch.to(device)\n",
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True, collate_fn=collate_batch)\n",
    "# val_loader = DataLoader(val_data, batch_size=128, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e08f4c2-e781-4cfb-9014-81012682097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['<unk>', '<pad>', '<sos>', '<eos>', '：', '“', '”', '的', '，', '#', '！', '？', '海南', '了', '海口', '、', '你', '将', '是', '10', '也', '人', '来', '法', '要', '让', '香港', '1', '7', '不', '与', '为', '后', '吗', '啦', '在', '多', '最高', '月', '有', '看', '第一', '被', '15', '2014', '3', 'CES', '今日', '全国', '办', '去', '发布', '可', '周末', '国家', '对', '少女', '岁', '年', '年货', '我', '新', '春节', '杨桃', '男子', '等', '网信', '能', '购物', '违规', '都', '-', '2', '2015', '24', '5', '9', ':', '\\xa0', '…', '一批', '三亚', '专项', '个', '主动', '之', '习', '交通事故', '产品', '人民', '代购', '们', '佩兰', '信心', '信息', '免费', '全面', '公布', '别买', '前', '加强', '千万', '只', '吃', '名', '向', '和', '场', '增至', '大', '大学生', '大桥', '失踪', '学生', '实施', '家长', '容易', '小心', '就', '展', '巡回', '工商总局', '已', '市场', '带', '平价', '开卖', '律师', '恋爱', '感动', '我们', '手机', '打造', '抗癌药', '报价', '排名', '推出', '摘', '支付', '政府', '施行', '日', '智能手机', '最高检', '未', '案件', '检方', '次', '死', '比赛', '汽车', '没', '河南', '法庭', '澄迈', '特里', '登革热', '皇马', '监督员', '称', '网上', '网站', '网络', '考虑', '者', '脱掉', '英媒', '获', '菜', '薄熙来', '街头', '西双版纳', '要求', '账号', '路', '身份证', '车祸', '这', '这个', '遇难', '遭', '郑州', '部门', '问题', '限']\n",
      "Vocabulary size: 185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 分词器\n",
    "def tokenizer(text):\n",
    "    return [tok for tok in jieba.cut(text)]\n",
    "\n",
    "# 自定义数据集类\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.tokenizer(self.data.iloc[idx, 1])\n",
    "        trg = self.tokenizer(self.data.iloc[idx, 0])\n",
    "        return {'src': src, 'trg': trg}\n",
    "\n",
    "# 读取数据并划分为训练集和验证集\n",
    "data = pd.read_csv('../data/data_sample.tsv', sep='\\t', header=0)\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据集实例\n",
    "train_dataset = TextDataset(train_data, tokenizer)\n",
    "val_dataset = TextDataset(val_data, tokenizer)\n",
    "\n",
    "# 创建词汇表\n",
    "def yield_tokens(data_iter):\n",
    "    for tokens in data_iter:\n",
    "        yield tokens\n",
    "\n",
    "# 使用训练数据构建词汇表\n",
    "vocab = build_vocab_from_iterator(yield_tokens(item['src'] for item in train_dataset),\n",
    "                                  min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "# 定义索引转换和特殊标记索引\n",
    "PAD_IDX = vocab['<pad>']\n",
    "UNK_IDX = vocab['<unk>']\n",
    "SOS_IDX = vocab['<sos>']\n",
    "EOS_IDX = vocab['<eos>']\n",
    "\n",
    "# 批次处理函数\n",
    "def collate_batch(batch):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for item in batch:\n",
    "        src_batch.append([SOS_IDX] + vocab(item['src']) + [EOS_IDX])\n",
    "        trg_batch.append([SOS_IDX] + vocab(item['trg']) + [EOS_IDX])\n",
    "    \n",
    "    src_batch = pad_sequence([torch.tensor(x) for x in src_batch], padding_value=PAD_IDX, batch_first=True)\n",
    "    trg_batch = pad_sequence([torch.tensor(x) for x in trg_batch], padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch.to(device), trg_batch.to(device)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "print(\"Vocabulary:\", vocab.get_itos())  # 检查词汇表内容\n",
    "print(\"Vocabulary size:\", len(vocab))   # 检查词汇表大小\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98475eeb-32f5-42a9-994a-93c3d790c955",
   "metadata": {},
   "source": [
    "## Multi-head Self-attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3a58b43-4db1-4ae0-9312-2432807d1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        assert hid_dim % n_heads == 0\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "    # input shape: [batch size, seq len, hid dim]\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "        # query = [batch size, query len, hid dim]\n",
    "        # key = [batch size, key len, hid dim]\n",
    "        # value = [batch size, value len, hid dim]\n",
    "        \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        # Q = [batch size, query len, hid dim]\n",
    "        # K = [batch size, key len, hid dim]\n",
    "        # V = [batch size, value len, hid dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        # Q = [batch size, n heads, query len, head dim]\n",
    "        # K = [batch size, n heads, key len, head dim]\n",
    "        # V = [batch size, n heads, value len, head dim]\n",
    "        \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        # energy = [batch size, n heads, query len, key len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "        # attention = [batch size, n heads, query len, key len]\n",
    "\n",
    "        # assert(key len == value len)\n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        # x = [batch size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        # x = [batch size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        # x = [batch size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        # x = [batch size, query len, hid dim]\n",
    "        \n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555313ba-8e3a-49f7-a8a5-5923ac7d0a13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 10, 512])\n",
      "Attention shape: torch.Size([2, 8, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# 定义模型参数\n",
    "hid_dim = 512  # 隐藏层维度\n",
    "n_heads = 8    # 多头注意力头数\n",
    "dropout = 0.1\n",
    "\n",
    "# 创建 MultiHeadAttentionLayer 实例\n",
    "model = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device).to(device)\n",
    "\n",
    "# 创建测试输入\n",
    "batch_size = 2      # 批量大小\n",
    "query_len = 10      # query 序列长度\n",
    "key_len = 10        # key 序列长度\n",
    "value_len = 10      # value 序列长度\n",
    "\n",
    "# 输入形状为 [batch size, seq len, hid dim]\n",
    "query = torch.rand(batch_size, query_len, hid_dim).to(device)\n",
    "key = torch.rand(batch_size, key_len, hid_dim).to(device)\n",
    "value = torch.rand(batch_size, value_len, hid_dim).to(device)\n",
    "\n",
    "# 执行前向传播并输出结果\n",
    "output, attention = model(query, key, value)\n",
    "\n",
    "print(\"Output shape:\", output.shape)        # 预期输出形状为 [batch size, query len, hid dim]\n",
    "print(\"Attention shape:\", attention.shape)  # 预期注意力形状为 [batch size, n heads, query len, key len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed73a7-bdc9-4ba8-859c-00b149a3826c",
   "metadata": {},
   "source": [
    "## Feed Forward Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a19f42b-b545-4df3-bc56-522eaeae02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        # x = [batch size, seq len, pf dim]\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        # x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa5ccbc-9601-4bce-ae02-9e8795deabe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10, 512])\n",
      "Output shape: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "hid_dim = 512   # 输入特征维度\n",
    "pf_dim = 2048   # 前馈网络的隐藏维度\n",
    "dropout = 0.1   # dropout 概率\n",
    "\n",
    "# 创建 PositionwiseFeedforwardLayer 实例\n",
    "ff_layer = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "\n",
    "# 创建测试输入张量\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "x = torch.rand(batch_size, seq_len, hid_dim)  # [batch size, seq len, hid dim]\n",
    "\n",
    "# 执行前向传播并打印结果\n",
    "output = ff_layer(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)        # 期望：[batch size, seq len, hid dim]\n",
    "print(\"Output shape:\", output.shape)  # 期望：[batch size, seq len, hid dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423c9ba-ce5c-4082-91e0-08bc89393bb9",
   "metadata": {},
   "source": [
    "## Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a94e2b6d-6399-4791-ade1-4d3f72b729b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hid_dim,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
    "                                                                     pf_dim,\n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # src = [batch size, src len, hid dim]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        # self attention\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        # dropout, residual connection and layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        # src = [batch size, src len, hid dim]\n",
    "        \n",
    "        # positionwise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "        # dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        # src = [batch size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bcdb916-89be-43fb-a099-90d144f83024",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10, 512])\n",
      "Output shape: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "hid_dim = 512\n",
    "n_heads = 8\n",
    "pf_dim = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "# 创建 EncoderLayer 实例\n",
    "encoder_layer = EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device).to(device)\n",
    "\n",
    "# 创建测试输入\n",
    "batch_size = 2\n",
    "src_len = 10\n",
    "\n",
    "# 输入数据和掩码\n",
    "src = torch.rand(batch_size, src_len, hid_dim).to(device)         # [batch size, src len, hid dim]\n",
    "src_mask = torch.ones(batch_size, 1, 1, src_len).to(device)       # [batch size, 1, 1, src len]\n",
    "\n",
    "# 执行前向传播\n",
    "output = encoder_layer(src, src_mask)\n",
    "\n",
    "print(\"Input shape:\", src.shape)       # 预期：[batch size, src len, hid dim]\n",
    "print(\"Output shape:\", output.shape)   # 预期：[batch size, src len, hid dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704e198-22c0-4d79-b927-64fe223f41ff",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f5353cd-d3b3-4244-9b70-c393bb9e214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hid_dim,\n",
    "                 n_layers,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device,\n",
    "                 max_length=500):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim,\n",
    "                                                  n_heads,\n",
    "                                                  pf_dim,\n",
    "                                                  dropout,\n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # src = [batch size, src len]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "\n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        # pos = [batch size, src len]\n",
    "        \n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        # src = [batch size, src len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "            # src = [batch size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2829b12-fc0e-4b51-8526-79262e375b0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Input shape: torch.Size([2, 10])\n",
      "Output shape: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# Parameters for testing\n",
    "input_dim = 1000  # Vocabulary size\n",
    "hid_dim = 512     # Embedding/hidden size\n",
    "n_layers = 1      # Number of encoder layers\n",
    "n_heads = 1       # Number of attention heads\n",
    "pf_dim = 2048     # Position-wise feedforward dimension\n",
    "dropout = 0.1     # Dropout probability\n",
    "src_len = 10      # Length of source sequence\n",
    "batch_size = 2    # Batch size\n",
    "\n",
    "# Initialize encoder with test parameters\n",
    "encoder = Encoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device).to(device)\n",
    "\n",
    "# Create random test input\n",
    "src = torch.randint(0, input_dim, (batch_size, src_len)).to(device)  # Random integers representing token IDs\n",
    "src_mask = torch.ones((batch_size, 1, 1, src_len)).to(device)        # Simple mask with ones\n",
    "\n",
    "# Test the encoder\n",
    "output = encoder(src, src_mask)\n",
    "print(\"Input shape:\", src.shape)       # 预期：[batch size, src len]\n",
    "print(\"Output shape:\", output.shape)   # 预期：[batch size, src len, hid dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65497d3b-ea64-4453-8e9f-359ad89508ff",
   "metadata": {},
   "source": [
    "## Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d031530-09c5-4c5f-8bdd-5b01265dd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hid_dim,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
    "                                                                     pf_dim,\n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # trg = [batch size, trg len, hid dim]\n",
    "        # enc_src = [batch size, src len, hid dim]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        # self attention\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        # dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        # trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        # encoder attention\n",
    "        # input: [query, key, value, mask]\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        # attention = [batch size, n heads, trg len, src len]\n",
    "        # dropout, residual connection and layer norm\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        # trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        # positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "        # dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        # trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d335313-aedf-40e2-8863-25561233c966",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10])\n",
      "Output shape: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# Parameters for testing\n",
    "hid_dim = 512     # Hidden dimension\n",
    "n_heads = 1       # Number of attention heads\n",
    "pf_dim = 2048     # Position-wise feedforward dimension\n",
    "dropout = 0.1     # Dropout probability\n",
    "trg_len = 10      # Length of target sequence\n",
    "src_len = 15      # Length of source sequence\n",
    "batch_size = 2    # Batch size\n",
    "\n",
    "# Initialize decoder layer with test parameters\n",
    "decoder_layer = DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device).to(device)\n",
    "\n",
    "# Create random test input\n",
    "trg = torch.rand(batch_size, trg_len, hid_dim).to(device)  # Target sequence\n",
    "enc_src = torch.rand(batch_size, src_len, hid_dim).to(device)  # Encoder source output\n",
    "trg_mask = torch.ones((batch_size, 1, trg_len, trg_len)).to(device)  # Target mask\n",
    "src_mask = torch.ones((batch_size, 1, 1, src_len)).to(device)  # Source mask\n",
    "\n",
    "# Test the decoder layer\n",
    "output, attention = decoder_layer(trg, enc_src, trg_mask, src_mask)\n",
    "print(\"Input shape:\", src.shape)       # 预期：[batch size, src len]\n",
    "print(\"Output shape:\", output.shape)   # 预期：[batch size, src len, hid dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8212c70-6457-4626-a6f2-c244307d7eaf",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b485b26f-1e62-4465-a0ff-710952df4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 hid_dim,\n",
    "                 n_layers,\n",
    "                 n_heads,\n",
    "                 pf_dim,\n",
    "                 dropout,\n",
    "                 device,\n",
    "                 max_length=500):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim,\n",
    "                                                  n_heads,\n",
    "                                                  pf_dim,\n",
    "                                                  dropout,\n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # trg = [batch size, trg len]\n",
    "        # enc_src = [batch size, src len, hid dim]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        # pos = [batch size, trg len]\n",
    "        \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        # trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            # trg = [batch size, trg len, hid dim]\n",
    "            # attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        # output = [batch size, trg len, output dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6795b5c1-5863-47a7-b0fa-53c963d1c82e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10])\n",
      "Output shape: torch.Size([2, 10, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Parameters for testing\n",
    "output_dim = 1000  # Output vocabulary size\n",
    "hid_dim = 512      # Hidden dimension\n",
    "n_layers = 1       # Number of decoder layers\n",
    "n_heads = 1        # Number of attention heads\n",
    "pf_dim = 2048      # Position-wise feedforward dimension\n",
    "dropout = 0.1      # Dropout probability\n",
    "trg_len = 10       # Length of target sequence\n",
    "src_len = 15       # Length of source sequence\n",
    "batch_size = 2     # Batch size\n",
    "\n",
    "# Initialize decoder with test parameters\n",
    "decoder = Decoder(output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device).to(device)\n",
    "\n",
    "# Create random test input\n",
    "trg = torch.randint(0, output_dim, (batch_size, trg_len)).to(device)  # Target sequence token IDs\n",
    "enc_src = torch.rand(batch_size, src_len, hid_dim).to(device)         # Encoder output\n",
    "trg_mask = torch.ones((batch_size, 1, trg_len, trg_len)).to(device)   # Target mask\n",
    "src_mask = torch.ones((batch_size, 1, 1, src_len)).to(device)         # Source mask\n",
    "\n",
    "# Test the decoder\n",
    "output, attention = decoder(trg, enc_src, trg_mask, src_mask)\n",
    "print(\"Input shape:\", trg.shape)       # 预期：[batch size, src len]\n",
    "print(\"Output shape:\", output.shape)   # 预期：[batch size, src len, hid dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6050b-532a-44d2-95f2-79bbff94cec5",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bce0937c-98a4-4a29-b229-a73b9727477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 pad_idx,\n",
    "                 device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # src = [batch size, src len]\n",
    "        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        # trg = [batch size, trg len]\n",
    "        trg_pad_mask = (trg != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
    "        # trg_sub_mask = [trg len, trg len]\n",
    "        \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        # src = [batch size, src len]\n",
    "        # trg = [batch size, trg len]\n",
    "        \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        # enc_src = [batch size, src len, hid dim]\n",
    "        \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        # output = [batch size, trg len, output dim]\n",
    "        # attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "056e7ed6-1d7c-424f-b566-587f91e0b7c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize encoder, decoder, and transformer\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Encoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 14\u001b[0m decoder \u001b[38;5;241m=\u001b[39m decoder \u001b[38;5;241m=\u001b[39m Decoder(\u001b[43moutput_dim\u001b[49m, hid_dim, n_layers, n_heads, pf_dim, dropout, device)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m transformer \u001b[38;5;241m=\u001b[39m Transformer(encoder, decoder, \u001b[38;5;241m0\u001b[39m, device)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create random test inputs\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters for testing\n",
    "input_dim = 1000  # Vocabulary size\n",
    "hid_dim = 512     # Embedding/hidden size\n",
    "n_layers = 1      # Number of encoder layers\n",
    "n_heads = 1       # Number of attention heads\n",
    "pf_dim = 2048     # Position-wise feedforward dimension\n",
    "dropout = 0.1     # Dropout probability\n",
    "src_len = 10      # Length of source sequence\n",
    "batch_size = 2    # Batch size\n",
    "\n",
    "\n",
    "# Initialize encoder, decoder, and transformer\n",
    "encoder = Encoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device).to(device)\n",
    "decoder = decoder = Decoder(output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device).to(device)\n",
    "transformer = Transformer(encoder, decoder, 0, device)\n",
    "\n",
    "# Create random test inputs\n",
    "src = torch.randint(0, output_dim, (batch_size, src_len))  # Random source sequence\n",
    "trg = torch.randint(0, output_dim, (batch_size, trg_len))  # Random target sequence\n",
    "\n",
    "# Test the transformer\n",
    "output, attention = transformer(src, trg)\n",
    "src.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf8b4179-c57e-4b50-a33c-18e8f85d247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'<unk>': 0, '<pad>': 1, '<sos>': 2, '<eos>': 3, '三亚': 4, '遭': 5, '了': 6, '？': 7, '海南': 8, '发布': 9, '工商总局': 10, '与': 11, '：': 12, '政府': 13, '要': 14, '加强': 15, '对': 16, '的': 17, '大': 18, '\\xa0': 19, '“': 20, '”': 21, '，': 22, '！': 23, '在': 24, '信息': 25, '7': 26, '来': 27, '路': 28, '人': 29, '2': 30, '场': 31, '佩兰': 32, '也': 33, '没': 34, '信心': 35, '3': 36, '最高检': 37, ':': 38, '未': 39, '是': 40, '排名': 41, '最高': 42, '英媒': 43, '报价': 44, '感动': 45, '2014': 46, '一批': 47, '交通事故': 48, '公布': 49, '习': 50, '有': 51, '法': 52, '第一': 53, '巡回': 54, '法庭': 55, '今日': 56, '多': 57, '部门': 58, '、': 59, '等': 60, '后': 61, '比赛': 62, '只': 63, '脱掉': 64, '推出': 65, '你': 66, '看': 67, '5': 68, '网络': 69, '者': 70, '都': 71, '小心': 72, '律师': 73, '称': 74, '可': 75, '名': 76, '车祸': 77, '遇难': 78, '网信': 79, '办': 80, '账号': 81, '将': 82, '施行': 83, '网站': 84, '违规': 85, '手机': 86, '去': 87, '智能手机': 88, '市场': 89, '1': 90, '主动': 91, '新': 92, '春节': 93, '前': 94, '皇马': 95, '开卖': 96, '为': 97, '问题': 98, '-': 99, '免费': 100, '啦': 101, '千万': 102, 'CES': 103, '2015': 104, '年': 105, '月': 106, '日': 107, '海口': 108, '让': 109, '我': 110, '就': 111, '死': 112, '男子': 113, '河南': 114, '平价': 115, '菜': 116, '能': 117, '吃': 118, '吗': 119, '全面': 120, '人民': 121, '监督员': 122, '10': 123, '大学生': 124, '限': 125, '24': 126, '#': 127, '香港': 128, '被': 129, '学生': 130, '全国': 131, '这': 132, '岁': 133, '恋爱': 134, '大桥': 135, '身份证': 136, '网上': 137, '向': 138, '15': 139, '失踪': 140, '少女': 141, '次': 142, '和': 143, '们': 144, '实施': 145, '…': 146, '之': 147, '购物': 148, '打造': 149, '要求': 150, '检方': 151, '不': 152, '抗癌药': 153, '代购': 154, '个': 155, '西双版纳': 156, '登革热': 157, '增至': 158, '别买': 159, '家长': 160, '薄熙来': 161, '我们': 162, '带': 163, '考虑': 164, '容易': 165, '澄迈': 166, '杨桃': 167, '这个': 168, '周末': 169, '摘': 170, '案件': 171, '郑州': 172, '街头': 173, '汽车': 174, '已': 175, '产品': 176, '9': 177, '国家': 178, '专项': 179, '特里': 180, '年货': 181, '展': 182, '支付': 183, '获': 184}\n",
      "Vocabulary size: 185\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 定义分词器\n",
    "def tokenizer(text):\n",
    "    return [tok for tok in jieba.cut(text)]\n",
    "\n",
    "\n",
    "# 自定义数据集类\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.tokenizer(self.data.iloc[idx, 1])\n",
    "        trg = self.tokenizer(self.data.iloc[idx, 0])\n",
    "        return {'src': src, 'trg': trg}\n",
    "\n",
    "\n",
    "# 读取数据并划分为训练集和验证集\n",
    "data = pd.read_csv('../data/data_sample.tsv', sep='\\t', header=0)\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据集实例\n",
    "train_dataset = TextDataset(train_data, tokenizer)\n",
    "val_dataset = TextDataset(val_data, tokenizer)\n",
    "\n",
    "\n",
    "# 构建词汇表\n",
    "def build_vocab(data, min_freq=2):\n",
    "    counter = Counter()\n",
    "    for item in data:\n",
    "        counter.update(item['src'])\n",
    "        # counter.update(item['trg'])\n",
    "    # 过滤低频词，只保留频率大于等于min_freq的词\n",
    "    filtered_words = [word for word, freq in counter.items() if freq >= min_freq]\n",
    "\n",
    "    # 为词汇表创建连续的索引，从4开始编号，保留特殊标记\n",
    "    vocab = {'<unk>': 0, '<pad>': 1, '<sos>': 2, '<eos>': 3}\n",
    "    vocab.update({word: idx for idx, word in enumerate(filtered_words, start=4)})\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "# 创建词汇表\n",
    "vocab = build_vocab(train_dataset, min_freq=2)\n",
    "\n",
    "# 定义索引转换和特殊标记索引\n",
    "PAD_IDX = vocab['<pad>']\n",
    "UNK_IDX = vocab['<unk>']\n",
    "SOS_IDX = vocab['<sos>']\n",
    "EOS_IDX = vocab['<eos>']\n",
    "\n",
    "\n",
    "# 批次处理函数\n",
    "def collate_batch(batch):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for item in batch:\n",
    "        src = [vocab.get(token, UNK_IDX) for token in item['src']]\n",
    "        trg = [vocab.get(token, UNK_IDX) for token in item['trg']]\n",
    "        src_batch.append([SOS_IDX] + src + [EOS_IDX])\n",
    "        trg_batch.append([SOS_IDX] + trg + [EOS_IDX])\n",
    "\n",
    "    src_batch = pad_sequence([torch.tensor(x) for x in src_batch], padding_value=PAD_IDX, batch_first=True)\n",
    "    trg_batch = pad_sequence([torch.tensor(x) for x in trg_batch], padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, trg_batch\n",
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "print(\"Vocabulary:\", vocab)  # 检查词汇表内容\n",
    "print(\"Vocabulary size:\", len(vocab))   # 检查词汇表大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f3de7-1a0f-4639-990d-4fae60716d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22a842f5-81a5-4dcf-ae0a-b259bd8effd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 0]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.69s/it, loss=2.38]\n",
      "[Eval Epoch 0: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.97it/s, loss=2.95]\n",
      "[Train Epoch 1]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.47s/it, loss=2.39]\n",
      "[Eval Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.89it/s, loss=2]\n",
      "[Train Epoch 2]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.72s/it, loss=2.06]\n",
      "[Eval Epoch 2: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.86it/s, loss=1.89]\n",
      "[Train Epoch 3]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.81s/it, loss=2.03]\n",
      "[Eval Epoch 3: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.95it/s, loss=1.91]\n",
      "[Train Epoch 4]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.65s/it, loss=1.98]\n",
      "[Eval Epoch 4: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.96it/s, loss=1.85]\n",
      "[Train Epoch 5]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.43s/it, loss=1.85]\n",
      "[Eval Epoch 5: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.94it/s, loss=1.87]\n",
      "[Train Epoch 6]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.33s/it, loss=1.96]\n",
      "[Eval Epoch 6: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.00it/s, loss=1.82]\n",
      "[Train Epoch 7]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.58s/it, loss=1.99]\n",
      "[Eval Epoch 7: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.87it/s, loss=1.83]\n",
      "[Train Epoch 8]: 100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.44s/it, loss=1.94]\n",
      "[Eval Epoch 8: 100%|████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.99it/s, loss=1.8]\n",
      "[Train Epoch 9]: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.62s/it, loss=2]\n",
      "[Eval Epoch 9: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.77it/s, loss=1.81]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model hyperparameters\n",
    "INPUT_DIM = len(vocab)\n",
    "OUTPUT_DIM = len(vocab)\n",
    "HID_DIM = 512\n",
    "ENC_LAYERS = 6\n",
    "DEC_LAYERS = 6\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 2048\n",
    "DEC_PF_DIM = 2048\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "# Instantiate encoder, decoder, and transformer model\n",
    "enc = Encoder(INPUT_DIM, HID_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "dec = Decoder(OUTPUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "model = Transformer(enc, dec, PAD_IDX, device).to(device)\n",
    "\n",
    "\n",
    "# Xavier 均匀分布初始化权重 weights\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# Track loss values for training and evaluation\n",
    "loss_vals = []\n",
    "loss_vals_eval = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "\n",
    "    # 添加进度条显示\n",
    "    pbar = tqdm(train_loader)\n",
    "    pbar.set_description(f\"[Train Epoch {epoch}]\")\n",
    "\n",
    "    for src, trg in pbar:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # trg[:, :-1] 去掉了目标序列中的最后一个位置，以确保模型只能看到部分的 trg 序列，并生成下一个单词。\n",
    "        # trg[:, 1:] 去掉了目标序列中的第一个位置，让模型逐步学习如何从已生成的部分生成下一个单词。\n",
    "        # trg = [<sos>, \"I\", \"love\", \"NLP\", <eos>]\n",
    "        # trg[:, :-1] = [<sos>, \"I\", \"love\", \"NLP\"]\n",
    "        # trg[:, 1:]  = [\"I\", \"love\", \"NLP\", <eos>]\n",
    "        output, _ = model(src, trg[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        # output = [batch_size * (trg_len - 1), output_dim]\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "        # trg = [batch_size * (trg_len - 1)]\n",
    "\n",
    "        # 模型中没有显式使用 softmax，但在损失计算时通过 CrossEntropyLoss 完成了 softmax 转换。\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        # 执行梯度裁剪，限制每个参数梯度的最大范数为 CLIP，防止梯度爆炸。\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    loss_vals.append(np.mean(epoch_loss))\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    epoch_loss_eval = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader)\n",
    "        pbar.set_description(f\"[Eval Epoch {epoch}\")\n",
    "\n",
    "        for src, trg in pbar:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output, _ = model(src, trg[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss_eval.append(loss.item())\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    loss_vals_eval.append(np.mean(epoch_loss_eval))\n",
    "\n",
    "# Save model\n",
    "# torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "# Plot the training and evaluation losses\n",
    "l1, = plt.plot(np.linspace(1, N_EPOCHS, N_EPOCHS).astype(int), loss_vals)\n",
    "l2, = plt.plot(np.linspace(1, N_EPOCHS, N_EPOCHS).astype(int), loss_vals_eval)\n",
    "plt.legend(handles=[l1, l2], labels=['Train loss', 'Eval loss'], loc='best')\n",
    "# plt.legend(handles=[l1], labels=['Train loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3080d32f-2eff-4b0a-ba8c-bf37ca40c7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['等', '佩兰', '等', '佩兰', '等', '佩兰', '等', '佩兰', '等', '佩兰', '等', '手机', '：', '遇难', '市场', '之', '周末', '在', '遇难', '市场', '吗', '车祸', '信心', '9', '！', '手机', '：', '遇难', '比赛', '在', '今日', '能', '7', '人', '在', '今日', '吃', '推出', '手机', '：', '遇难', '比赛', '在', '今日', '让', '千万', '：', '遇难', '比赛', '在']\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "OUTPUT_DIM = len(vocab)\n",
    "HID_DIM = 512\n",
    "ENC_LAYERS = 6\n",
    "DEC_LAYERS = 6\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 2048\n",
    "DEC_PF_DIM = 2048\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "# 初始化编码器、解码器和Transformer模型\n",
    "# enc = Encoder(INPUT_DIM, HID_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "# dec = Decoder(OUTPUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "# model = Transformer(enc, dec, PAD_IDX, device).to(device)\n",
    "\n",
    "# 加载预训练模型\n",
    "# model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()\n",
    "\n",
    "# 输入句子并分词\n",
    "sent = '中新网9月19日电据英国媒体报道,当地时间19日,苏格兰公投结果出炉,55%选民投下反对票,对独立说“不”。在结果公布前,英国广播公司(BBC)预测,苏格兰选民以55%对45%投票反对独立。'\n",
    "tokens = [tok for tok in jieba.cut(sent)]\n",
    "tokens = ['<sos>'] + tokens + ['<eos>']\n",
    "\n",
    "# 将分词转换为词汇表索引\n",
    "src_indexes = [vocab.get(token, UNK_IDX) for token in tokens]\n",
    "src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "src_mask = model.make_src_mask(src_tensor)\n",
    "\n",
    "# 编码输入句子\n",
    "with torch.no_grad():\n",
    "    enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "# 初始化目标序列的索引列表\n",
    "trg_indexes = [SOS_IDX]\n",
    "\n",
    "# 逐步生成翻译结果\n",
    "for i in range(50):\n",
    "    trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "    trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "    pred_token = output.argmax(2)[:,-1].item()\n",
    "    trg_indexes.append(pred_token)\n",
    "\n",
    "    if pred_token == EOS_IDX:\n",
    "        break\n",
    "\n",
    "# 将目标序列的索引转换回词汇表的词汇\n",
    "trg_tokens = [list(vocab.keys())[list(vocab.values()).index(i)] for i in trg_indexes]\n",
    "\n",
    "# 输出结果（去除<sos>标记）\n",
    "print(trg_tokens[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf128808-b8d3-4705-a3e1-e246538ce794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cpu] *",
   "language": "python",
   "name": "conda-env-pytorch_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
